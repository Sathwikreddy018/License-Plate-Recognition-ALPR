License Plate Recognition (ALPR) System
This repository contains the implementation of an Automatic License Plate Recognition (ALPR) system, developed as an assignment for the Data Scientist Intern position at Soulpage IT Solutions Pvt. Ltd. The system is designed to detect license plates in vehicle images and then recognize the alphanumeric characters on them.

Table of Contents
Problem Statement

Dataset Overview

System Architecture

Project Structure

Setup and Installation

Usage

Evaluation Criteria & Results

Challenges and Insights

Future Work

1. Problem Statement
The primary goal of this assignment is to develop a robust system for:

Detecting and locating vehicle license plates within images.

Performing character recognition on the detected license plates to decipher the alphanumeric text.

2. Dataset Overview
The project utilizes three distinct datasets:

Training Set 1 (900 images): Contains vehicle images with corresponding bounding box annotations (ymin, xmin, ymax, xmax) for license plates. Used for training the detection model.

Training Set 2 (900 images): Consists solely of license plate images with alphanumeric text annotations. Used for training/fine-tuning the character recognition model (though for this project, EasyOCR is used as a pre-trained solution).

Test Set (201 images): Structured similarly to Training Set 1 (vehicle images with LPs). Used to evaluate the end-to-end system's performance in both detection and character recognition.

Table 1: LPR Dataset Summary

Dataset Name

Image Count

Content Description

Annotation Type

Primary Purpose

Training Set 1

900

Vehicle images with LPs

Bounding Box (ymin, xmin, ymax, xmax)

License Plate Detection Training

Training Set 2

900

License plate images

Alphanumeric Text

Character Recognition Training

Test Set

201

Vehicle images with LPs

N/A (for evaluation)

Integrated System Evaluation

3. System Architecture
The ALPR system is implemented as a two-stage pipeline:

License Plate Detection:

Model: YOLOv8n (nano version) from Ultralytics.

Training: Trained on Training Set 1 (900 images) after converting annotations to YOLO format.

Function: Identifies and localizes the license plate within a given vehicle image, outputting bounding box coordinates.

Character Recognition (OCR):

Model: EasyOCR (pre-trained).

Post-processing: A custom function is applied to clean and refine the raw OCR output, handling common errors and non-alphanumeric characters.

Function: Extracts alphanumeric text from the cropped license plate images.

The end-to-end pipeline processes a test image by first detecting the license plate using YOLOv8, then cropping the detected region, and finally applying EasyOCR with post-processing to recognize the text.

4. Project Structure
The repository is organized as follows:

license_plate_recognition_project/
├── data/
│   ├── train_set_1/
│   │   ├── images/         # 900 vehicle images
│   │   └── annotations.csv # Bounding box annotations for train_set_1
│   ├── train_set_2/
│   │   └── images/         # 900 cropped license plate images
│   └── test_set/
│       ├── images/         # 201 test vehicle images
│       └── test_labels.csv # Placeholder for actual ground truth labels (for evaluation)
├── yolo_data/              # Generated during data preparation (YOLO format)
│   ├── images/
│   │   ├── train/          # Training images for YOLO
│   │   └── val/            # Validation images for YOLO
│   ├── labels/
│   │   ├── train/          # YOLO format labels for training
│   │   └── val/            # YOLO format labels for validation
│   └── dataset.yaml        # YOLOv8 dataset configuration file
├── ocr_model/
│   └── model_weights/
│       └── yolov8_license_plate_detector.pt # Trained YOLOv8 weights
├── outputs/                # Generated during inference
│   ├── cropped_plates/     # Cropped license plate images from test set
│   ├── visualizations/     # Original test images with detected bounding boxes
│   └── predictions.csv     # Final license plate recognition predictions for test set
├── notebooks/
│   └── License_Plate_Recognition.ipynb # Main Jupyter Notebook with full pipeline
├── runs/                   # Automatically generated by Ultralytics YOLOv8 training
│   └── detect/
│       └── license_plate_detector_v8n/ # Training logs, plots, and weights (best.pt, last.pt)
├── .gitignore              # Git ignore file (optional, but good practice)
└── requirements.txt        # List of Python dependencies

5. Setup and Installation
To set up the project and install the necessary dependencies, follow these steps:

Clone the repository:

git clone <repository_url>
cd license_plate_recognition_project

(Note: Replace <repository_url> with the actual URL if you put this on GitHub/GitLab.)

Create a virtual environment (recommended):

python -m venv venv
# On Windows:
.\venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate

Install dependencies:

pip install -r requirements.txt

(If requirements.txt is not provided, you would manually install: ultralytics, easyocr, opencv-python, pandas, scikit-learn, numpy, matplotlib)

Download Dataset:

Download the provided dataset from the Google Drive link: https://drive.google.com/drive/folders/1ThHnUQjkCNTOKXnvySVfpHZxZbYsFfMQ

Place the data folder (containing train_set_1, train_set_2, test_set) into the root of this project directory. Ensure the structure matches the Project Structure section above.

6. Usage
The entire ALPR pipeline is documented and executable within the License_Plate_Recognition.ipynb Jupyter Notebook.

To run the pipeline:

Start Jupyter Notebook:

jupyter notebook

Open the Notebook: Navigate to notebooks/License_Plate_Recognition.ipynb and open it.

Run All Cells: Execute all cells in the notebook sequentially (Kernel -> Restart & Run All).

Note on Training: The YOLOv8 model training (Section 4) can take several hours on a CPU. If the model has been trained previously and ocr_model/model_weights/yolov8_license_plate_detector.pt exists, you can interrupt the training cell after it starts to save time, as the weights are already available.

Output Files: Upon successful execution, the following will be generated:

yolo_data/: Prepared dataset for YOLOv8 training.

ocr_model/model_weights/yolov8_license_plate_detector.pt: The trained YOLOv8 detection model.

outputs/cropped_plates/: Cropped license plate images from the test set.

outputs/visualizations/: Test images with detected bounding boxes.

outputs/predictions.csv: The final predicted license plate texts for the test set.

7. Evaluation Criteria & Results
The assignment's evaluation is based on the accuracy of character recognition from the license plates.

Evaluation Metrics:

Character-level Accuracy: Percentage of correctly recognized characters.

Exact Plate Match Accuracy: Percentage of license plates where the entire predicted string perfectly matches the ground truth.

Local Evaluation with Mock Data:
For local testing, the evaluation script (License_Plate_Recognition.ipynb Section 7) automatically generates a test_labels.csv with placeholder UNKNOWN_PLATE values if a real ground truth file is not present. Therefore, the accuracy reported in the notebook will be very low (e.g., 0.15% character accuracy, 0.00% exact match).

Actual Evaluation by Soulpage IT Solutions:
Soulpage IT Solutions will use their own hidden ground truth labels for the Test Set to assess the true performance of the system. The outputs/predictions.csv generated by this pipeline is the key deliverable for this evaluation.

8. Challenges and Insights
Training Time on CPU: Training deep learning models like YOLOv8 can be computationally intensive, requiring significant time when performed on a CPU.

OCR Output Noise: Raw output from general-purpose OCR models often contains noise (e.g., symbols, misinterpretations). Robust post-processing is crucial to clean and standardize the recognized text for specific domains like license plates.

Pipeline Dependency: The overall accuracy of the ALPR system is highly dependent on the performance of both the detection and recognition stages. Errors in detection (e.g., missed plates, incorrect bounding boxes) directly impact the quality of the OCR input.

9. Future Work
To further enhance this ALPR system, the following areas could be explored:

Refined OCR Model:

Fine-tune EasyOCR or train a custom OCR model (e.g., using CRNN architectures) specifically on Training Set 2 for improved accuracy on diverse license plate fonts and styles.

Develop more advanced post-processing logic based on detailed error analysis and known license plate patterns.

Detection Model Optimization:

Experiment with larger YOLOv8 model variants (e.g., YOLOv8s, YOLOv8m) if computational resources allow, to potentially improve detection accuracy.

Optimize model hyperparameters and potentially fine-tune on a more diverse detection dataset.

Robustness to Environmental Factors:

Implement more aggressive data augmentation (e.g., varying lighting, blur, rotation) during training to enhance the system's performance under challenging real-world conditions.

Explore image pre-processing techniques (e.g., contrast enhancement, de-blurring) to improve image quality before detection and OCR.

Performance Optimization:

Optimize the inference pipeline for speed, potentially by converting models to ONNX or TensorRT formats for faster deployment.

Efficiently manage memory and computational resources.

Handling Multiple Plates & Edge Cases:

Implement logic to manage scenarios with multiple license plates in a single image, selecting the most relevant one or processing all.

Improve handling of partially obscured, damaged, or extremely angled plates.

User Interface/Deployment:

Develop a simple web interface (e.g., using Flask or Streamlit) for interactive demonstration.

Containerize the application using Docker for easier deployment and portability.

This project provides a strong foundation for a functional ALPR system, with clear pathways for future enhancements and optimizations.